{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/soe/hlitz/maxwell/notebooks/Prefetching_SSD/Data/output/MSR-Cambridge/Part2/src1_1.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import metrics\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from numpy import insert\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "path  = r\"/soe/hlitz/maxwell/notebooks/Prefetching_SSD/Data/output/MSR-Cambridge/Part2\" \n",
    "\n",
    "names = ['TimeStamp','Host_Name','DiskNumber','Operation_Type','ByteOffset','IOSize','Response_Time','DiskNum']\n",
    "\n",
    "\n",
    "#['TimeStamp','Response','IOType','LUN','ByteOffset','Size']\n",
    "\n",
    "\n",
    "all_files = glob.glob(os.path.join(path, \"src1_1.csv\"))\n",
    "print(all_files)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45746221\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(all_files[0],engine='python',skiprows =2,header=None,na_values=['-1'], index_col=False) \n",
    "names = ['TimeStamp','Host_Name','DiskNumber','Operation_Type','ByteOffset','IOSize','Response_Time','DiskNum']\n",
    "df.columns = names\n",
    "print (len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "6170590\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(len(Counter(df['IOSize'])))\n",
    "print(len(Counter(df['ByteOffset'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['ByteOffset_Delta'] = df['ByteOffset'] - df['ByteOffset'].shift(-1)\n",
    "df = df.drop(df.index[-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeStamp             int64\n",
      "Host_Name            object\n",
      "DiskNumber          float64\n",
      "Operation_Type       object\n",
      "ByteOffset            int64\n",
      "IOSize                int64\n",
      "Response_Time         int64\n",
      "DiskNum               int64\n",
      "ByteOffset_Delta    float64\n",
      "dtype: object\n",
      "45746220\n"
     ]
    }
   ],
   "source": [
    "#Sorting df by TimeStamp\n",
    "\n",
    "df = df.sort_values(by=['TimeStamp'])\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "print(df.dtypes)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ByteOffset_Delta'] = df['ByteOffset_Delta'].fillna(0)\n",
    "\n",
    "a = df['ByteOffset_Delta'].unique().tolist()\n",
    "operation_id_map = {}\n",
    "for i,id in enumerate(a): operation_id_map[id] = i \n",
    "df['ByteOffset_Delta_class'] = df['ByteOffset_Delta'].map(lambda x: operation_id_map[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Host_Name</th>\n",
       "      <th>DiskNumber</th>\n",
       "      <th>Operation_Type</th>\n",
       "      <th>ByteOffset</th>\n",
       "      <th>IOSize</th>\n",
       "      <th>Response_Time</th>\n",
       "      <th>DiskNum</th>\n",
       "      <th>ByteOffset_Delta</th>\n",
       "      <th>ByteOffset_Delta_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128166372013535022</td>\n",
       "      <td>src1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write</td>\n",
       "      <td>3337596928</td>\n",
       "      <td>65536</td>\n",
       "      <td>3543</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.871325e+10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128166372013536418</td>\n",
       "      <td>src1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write</td>\n",
       "      <td>102050844672</td>\n",
       "      <td>4096</td>\n",
       "      <td>2148</td>\n",
       "      <td>1</td>\n",
       "      <td>9.887073e+10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128166372013537059</td>\n",
       "      <td>src1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write</td>\n",
       "      <td>3180109824</td>\n",
       "      <td>8192</td>\n",
       "      <td>1507</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.192000e+03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128166372021660589</td>\n",
       "      <td>src1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write</td>\n",
       "      <td>3180118016</td>\n",
       "      <td>28672</td>\n",
       "      <td>2925</td>\n",
       "      <td>1</td>\n",
       "      <td>2.598093e+07</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128166372021662159</td>\n",
       "      <td>src1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write</td>\n",
       "      <td>3154137088</td>\n",
       "      <td>4096</td>\n",
       "      <td>1355</td>\n",
       "      <td>1</td>\n",
       "      <td>1.228800e+04</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TimeStamp Host_Name  DiskNumber Operation_Type    ByteOffset  \\\n",
       "0  128166372013535022      src1         NaN          Write    3337596928   \n",
       "1  128166372013536418      src1         NaN          Write  102050844672   \n",
       "2  128166372013537059      src1         NaN          Write    3180109824   \n",
       "3  128166372021660589      src1         NaN          Write    3180118016   \n",
       "4  128166372021662159      src1         NaN          Write    3154137088   \n",
       "\n",
       "   IOSize  Response_Time  DiskNum  ByteOffset_Delta  ByteOffset_Delta_class  \n",
       "0   65536           3543        1     -9.871325e+10                       0  \n",
       "1    4096           2148        1      9.887073e+10                       1  \n",
       "2    8192           1507        1     -8.192000e+03                       2  \n",
       "3   28672           2925        1      2.598093e+07                       3  \n",
       "4    4096           1355        1      1.228800e+04                       4  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "x = Counter(df['ByteOffset_Delta_class'])\n",
    "vals = {}\n",
    "vals =  x.most_common(1000)\n",
    "bo_list = []\n",
    "\n",
    "for x in vals:\n",
    "    bo_list.append(x[0])\n",
    "        \n",
    "count = 0\n",
    "label_list = []\n",
    "\n",
    "while (count < len(df)):\n",
    "    x = df['ByteOffset_Delta_class'].iloc[count]\n",
    "    if x in bo_list:\n",
    "        label_list.append(x)\n",
    "    else:\n",
    "        label_list.append(999999)\n",
    "    count= count + 1\n",
    "    \n",
    "ByteOffset_Delta_class_backup  = df['ByteOffset_Delta_class'] \n",
    "df['ByteOffset_Delta_class']  = label_list\n",
    "print(len(Counter(df['ByteOffset_Delta_class'])))\n",
    "    \n",
    "a = df['ByteOffset_Delta_class'].unique().tolist()\n",
    "bo_map = {}\n",
    "for i,id in enumerate(a): bo_map[id] = i \n",
    "df['ByteOffset_Delta_Class_1001'] = df['ByteOffset_Delta_class'].map(lambda x: bo_map[x])\n",
    "    \n",
    "label_list = df['ByteOffset_Delta_Class_1001'] \n",
    "    \n",
    "df['ByteOffset_Delta_Class_1001']  = label_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "count  = 0\n",
    "size_dec_norm = []\n",
    "size_dec = df['IOSize'].tolist()\n",
    "min_size = min(size_dec)\n",
    "max_size = max(size_dec)\n",
    "while (count < len(size_dec)):\n",
    "    tmp = (float(size_dec[count])- min_size)/(max_size - min_size)\n",
    "    count  = count +1\n",
    "    size_dec_norm.append(tmp)\n",
    "    \n",
    "df['Size'] = size_dec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Size'] = size_dec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(df['ByteOffset_Delta_Class_1001']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(df['Size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStamp                        int64\n",
       "Host_Name                       object\n",
       "DiskNumber                     float64\n",
       "Operation_Type                  object\n",
       "ByteOffset                       int64\n",
       "IOSize                           int64\n",
       "Response_Time                    int64\n",
       "DiskNum                          int64\n",
       "ByteOffset_Delta               float64\n",
       "ByteOffset_Delta_class           int64\n",
       "ByteOffset_Delta_Class_1001      int64\n",
       "Size                           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Host_Name</th>\n",
       "      <th>DiskNumber</th>\n",
       "      <th>Operation_Type</th>\n",
       "      <th>ByteOffset</th>\n",
       "      <th>IOSize</th>\n",
       "      <th>Response_Time</th>\n",
       "      <th>DiskNum</th>\n",
       "      <th>ByteOffset_Delta</th>\n",
       "      <th>ByteOffset_Delta_class</th>\n",
       "      <th>ByteOffset_Delta_Class_1001</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128166372013535022</td>\n",
       "      <td>src1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write</td>\n",
       "      <td>3337596928</td>\n",
       "      <td>65536</td>\n",
       "      <td>3543</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.871325e+10</td>\n",
       "      <td>999999</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128166372013536418</td>\n",
       "      <td>src1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write</td>\n",
       "      <td>102050844672</td>\n",
       "      <td>4096</td>\n",
       "      <td>2148</td>\n",
       "      <td>1</td>\n",
       "      <td>9.887073e+10</td>\n",
       "      <td>999999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128166372013537059</td>\n",
       "      <td>src1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write</td>\n",
       "      <td>3180109824</td>\n",
       "      <td>8192</td>\n",
       "      <td>1507</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.192000e+03</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128166372021660589</td>\n",
       "      <td>src1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write</td>\n",
       "      <td>3180118016</td>\n",
       "      <td>28672</td>\n",
       "      <td>2925</td>\n",
       "      <td>1</td>\n",
       "      <td>2.598093e+07</td>\n",
       "      <td>999999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128166372021662159</td>\n",
       "      <td>src1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Write</td>\n",
       "      <td>3154137088</td>\n",
       "      <td>4096</td>\n",
       "      <td>1355</td>\n",
       "      <td>1</td>\n",
       "      <td>1.228800e+04</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.055118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TimeStamp Host_Name  DiskNumber Operation_Type    ByteOffset  \\\n",
       "0  128166372013535022      src1         NaN          Write    3337596928   \n",
       "1  128166372013536418      src1         NaN          Write  102050844672   \n",
       "2  128166372013537059      src1         NaN          Write    3180109824   \n",
       "3  128166372021660589      src1         NaN          Write    3180118016   \n",
       "4  128166372021662159      src1         NaN          Write    3154137088   \n",
       "\n",
       "   IOSize  Response_Time  DiskNum  ByteOffset_Delta  ByteOffset_Delta_class  \\\n",
       "0   65536           3543        1     -9.871325e+10                  999999   \n",
       "1    4096           2148        1      9.887073e+10                  999999   \n",
       "2    8192           1507        1     -8.192000e+03                       2   \n",
       "3   28672           2925        1      2.598093e+07                  999999   \n",
       "4    4096           1355        1      1.228800e+04                       4   \n",
       "\n",
       "   ByteOffset_Delta_Class_1001      Size  \n",
       "0                            0  1.000000  \n",
       "1                            0  0.055118  \n",
       "2                            1  0.118110  \n",
       "3                            0  0.433071  \n",
       "4                            2  0.055118  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop: Index(['TimeStamp', 'Host_Name', 'DiskNumber', 'Operation_Type', 'ByteOffset',\n",
      "       'IOSize', 'Response_Time', 'DiskNum', 'ByteOffset_Delta',\n",
      "       'ByteOffset_Delta_class', 'ByteOffset_Delta_Class_1001', 'Size'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary coloumns\n",
    "\n",
    "print(\"Before drop: {}\".format(df.columns))\n",
    "df.drop(df.columns[[0,1,2,3,4,5,6,7,8,9]], axis=1,inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ByteOffset_Delta_Class_1001      int64\n",
       "Size                           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(len(Counter(df['Size'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(len(Counter(df['ByteOffset_Delta_Class_1001'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to train, validate and test\n",
    "\n",
    "# Finding the value 75th percentile of TimeStamp\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "training_pt_1 = math.floor((len(df)*0.75)) \n",
    "\n",
    "lba_train =df[:training_pt_1]['ByteOffset_Delta_Class_1001'].tolist()\n",
    "lba_test = df[training_pt_1+1:]['ByteOffset_Delta_Class_1001'].tolist()\n",
    "size_train = df[:training_pt_1]['Size'].tolist()\n",
    "size_test = df[training_pt_1+1:]['Size'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lba_train= np.array(lba_train).reshape(-1,1)\n",
    "lba_test= np.array(lba_test).reshape(-1,1)\n",
    "size_train= np.array(size_train).reshape(-1,1)\n",
    "size_test= np.array(size_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset2(dataset, window_size):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - 2 * window_size):\n",
    "        a = dataset[i:(i + window_size), 0]\n",
    "        #print(a)\n",
    "        dataX.append(a)\n",
    "        b = dataset[(i + window_size):(i + 2* window_size), 0]\n",
    "        #print(b)\n",
    "        dataY.append(b)\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "lstm_num_timesteps = 32\n",
    "    \n",
    "X_train_lba, y_train_lba = create_dataset2(lba_train, lstm_num_timesteps)\n",
    "X_test_lba, y_test_lba = create_dataset2(lba_test, lstm_num_timesteps)\n",
    "X_train_size, y_train_size = create_dataset2(size_train, lstm_num_timesteps)\n",
    "X_test_size, y_test_size = create_dataset2(size_test, lstm_num_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34309601, 32), (34309601, 32), (11436490, 32), (11436490, 32))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lba.shape, y_train_lba.shape, X_test_lba.shape,  y_test_lba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34309601, 32), (34309601, 32), (11436490, 32), (11436490, 32))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_size.shape, y_train_size.shape, X_test_size.shape,  y_test_size.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_num_features = 1\n",
    "lstm_predict_sequences = True\n",
    "lstm_num_predictions = 32\n",
    "\n",
    "\n",
    "# X_train = np.reshape(X_train, (X_train.shape[0], lstm_num_timesteps, lstm_num_features))\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], lstm_num_timesteps, lstm_num_features))\n",
    "    \n",
    "\n",
    "y_train_lba = np.reshape(y_train_lba, (y_train_lba.shape[0], lstm_num_predictions, lstm_num_features))\n",
    "y_test_lba = np.reshape(y_test_lba, (y_test_lba.shape[0], lstm_num_predictions, lstm_num_features))\n",
    "y_train_size = np.reshape(y_train_size, (y_train_size.shape[0], lstm_num_predictions, lstm_num_features))\n",
    "y_test_size = np.reshape(y_test_size, (y_test_size.shape[0], lstm_num_predictions, lstm_num_features))                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two classification outputs\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate , Dot\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout, TimeDistributed, Reshape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# no_docs = len(y_train_lba)\n",
    "maxlen= 32\n",
    "\n",
    "\n",
    "\n",
    "# # define two sets of inputs\n",
    "# inputA = Input(shape=(32,))\n",
    "# inputB = Input(shape=(32,))\n",
    "# # inputA = Sequential()\n",
    "# # inputB = Sequential()\n",
    "vocabulary_1 = len(Counter(df['ByteOffset_Delta_Class_1001']))\n",
    "\n",
    "\n",
    "hidden_size = 200\n",
    "\n",
    "# input=Input(shape=(no_docs,maxlen),dtype='float64')\n",
    "inputA=Input(shape=(maxlen,),dtype='float64')  \n",
    "inputB=Input(shape=(maxlen,),dtype='float64') \n",
    "\n",
    "\n",
    "# the first branch operates on the first input\n",
    "x = Embedding(input_dim=vocabulary_1,output_dim=hidden_size,input_length=maxlen)(inputA)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "\n",
    "# # the second branch opreates on the second input\n",
    "y = Embedding(input_dim=vocabulary_2,output_dim=hidden_size,input_length=maxlen)(inputB)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "# combine the output of the two branches\n",
    "combined = keras.layers.concatenate([x.output, y.output])\n",
    "\n",
    "lstm1 = LSTM(hidden_size,return_sequences=True)(combined)\n",
    "lstm2 = LSTM(hidden_size, return_sequences=True)(lstm1)\n",
    "\n",
    "# create classification output\n",
    "offset = keras.layers.wrappers.TimeDistributed(Dense(units=vocabulary_1, activation='softmax'), name='offset')(lstm2)\n",
    "iosize = keras.layers.wrappers.TimeDistributed(Dense(units=1, activation='sigmoid'), name='iosize')(lstm2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model =Model([inputA,inputB],[offset,iosize]) # combining all into a Keras model\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'offset': 'sparse_categorical_crossentropy', 'iosize': 'mse'},\n",
    "              loss_weights={'offset': 2., 'iosize': 1.5},\n",
    "              metrics={ 'offset': 'categorical_accuracy', 'iosize': 'mae'})\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/soe/hlitz/miniconda3/envs/py3_tf_gpu/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      " 9518080/34309601 [=======>......................] - ETA: 21:01:24 - loss: 3.5675 - offset_loss: 1.7264 - iosize_loss: 0.0765 - offset_categorical_accuracy: 0.9661 - iosize_mae: 0.1993"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "monitor = EarlyStopping(monitor='loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=1, save_best_only=True) # save best model\n",
    "\n",
    "\n",
    "print('Train...')\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit([X_train_lba,X_train_size],[y_train_lba,y_train_size],\n",
    "          verbose=1,epochs=75,callbacks=[monitor,checkpointer])\n",
    "\n",
    "# model.load_weights('best_weights.hdf5') # load weights from best model\n",
    "print('Done ...!')\n",
    "\n",
    "#model.fit(X_train, y_train, nb_epoch = num_epochs, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1,pred2 = model.predict([x_test_lba,x_test_size],verbose =1 )\n",
    "# pred_1 = np.argmax(pred1,axis=1)\n",
    "# pred_2 = np.argmax(pred2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "max_lba_accuracy = 0\n",
    "max_lba_accuracy_pos = 0\n",
    "\n",
    "max_size_accuracy = 0\n",
    "max_size_accuracy_pos = 0\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(32):\n",
    "    pred_1 = pred1[:,i,:]\n",
    "    pred_2 = pred2[:,i,:]\n",
    "    pred_1 = np.argmax(pred_1, axis=1)\n",
    "    pred_2 = np.argmax(pred_2, axis=1)\n",
    "    \n",
    "    \n",
    "    tmp_lba = accuracy_score(lba_test_final, pred_1)\n",
    "    if (tmp_lba > max_lba_accuracy):\n",
    "        max_lba_accuracy = tmp_lba\n",
    "        max_lba_accuracy_pos = i\n",
    "        \n",
    "    tmp_size = accuracy_score(lba_size_final, pred_2)\n",
    "    if (tmp_size > max_size_accuracy):\n",
    "        max_size_accuracy = tmp_size\n",
    "        max_size_accuracy_pos = i\n",
    "    \n",
    "\n",
    "print(\"Best IO Size Accuracy\", str(max_size_accuracy))\n",
    "print(\"Best IO Size Pos\", str(max_size_accuracy_pos))\n",
    "\n",
    "print(\"Best LBA Delta Accuracy\", str(max_lba_accuracy))\n",
    "print(\"Best LBA Delta Position\", str(max_lba_accuracy_pos))\n",
    "\n",
    "print(\"Elapsed time: {}\".format((elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done...!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3_tf_gpu] *",
   "language": "python",
   "name": "conda-env-py3_tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
