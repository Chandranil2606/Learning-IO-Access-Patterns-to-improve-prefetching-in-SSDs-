{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/soe/hlitz/maxwell/notebooks/Prefetching_SSD/Data/output/Buildserver/data-output-buildserver-7_total.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import metrics\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from numpy import insert\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path  = r\"/soe/hlitz/maxwell/notebooks/Prefetching_SSD/Data/output/Buildserver/\" \n",
    "\n",
    "names = ['Operation','TimeStamp','Process_Name','ThreadID','IrpPtr','ByteOffset','IOSize','ThreadID','ElapsedTime','DiskNum','IrpFlags','DiskSvcTime','I/O Pri','VolSnap','FileObject','FileName','IO_Pri']\n",
    "\n",
    "\n",
    "\n",
    "all_files = glob.glob(os.path.join(path, \"data-output-buildserver-7_total.csv\"))\n",
    "print(all_files)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714289\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(all_files[0],engine='python',skiprows =1,header=None,na_values=['-1'], index_col=False) \n",
    "names = ['Operation','TimeStamp','Process_Name','ThreadID','IrpPtr','ByteOffset','IOSize','ThreadID','ElapsedTime','DiskNum','IrpFlags','DiskSvcTime','I/O Pri','VolSnap','FileObject','FileName','IO_Pri']\n",
    "df.columns = names\n",
    "print (len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation        object\n",
      "TimeStamp        object\n",
      "Process_Name     object\n",
      "ThreadID         object\n",
      "IrpPtr           object\n",
      "ByteOffset       object\n",
      "IOSize           object\n",
      "ThreadID         object\n",
      "ElapsedTime      object\n",
      "DiskNum          object\n",
      "IrpFlags         object\n",
      "DiskSvcTime      object\n",
      "I/O Pri         float64\n",
      "VolSnap          object\n",
      "FileObject       object\n",
      "FileName         object\n",
      "IO_Pri           object\n",
      "dtype: object\n",
      "714289\n"
     ]
    }
   ],
   "source": [
    "#Sorting df by TimeStamp\n",
    "\n",
    "df = df.sort_values(by=['TimeStamp'])\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "print(df.dtypes)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714151\n",
      "714151\n"
     ]
    }
   ],
   "source": [
    "addresses = df['ByteOffset'].tolist()\n",
    "size = df['IOSize'].tolist()\n",
    "addresses_dec = []\n",
    "size_dec = []\n",
    "count = 0\n",
    "\n",
    "while (count < len(addresses)):\n",
    "    if \"Offset\" in addresses[count]:\n",
    "        count = count +1\n",
    "        continue\n",
    "    dec = addresses[count]\n",
    "    dec_size = addresses[count]\n",
    "    tmp = int(dec, 16)\n",
    "    tmp_size = int(dec_size,16)\n",
    "    addresses_dec.append(tmp)\n",
    "    size_dec.append(tmp_size)\n",
    "    count = count +1\n",
    "    \n",
    "print(len(addresses_dec))\n",
    "print(len(size_dec))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n",
      "396736\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(len(Counter(df['IOSize'])))\n",
    "print(len(Counter(df['ByteOffset'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "count  = 0\n",
    "size_dec_norm = []\n",
    "min_size = min(size_dec)\n",
    "max_size = max(size_dec)\n",
    "while (count < len(size_dec) ):\n",
    "    tmp = (float(size_dec[count])- min_size)/(max_size - min_size)\n",
    "    count  = count +1\n",
    "    size_dec_norm.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714151"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(size_dec_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = pd.DataFrame(columns = ['ByteOffset', 'IOSize']) \n",
    "\n",
    "df_a['ByteOffset'] = addresses_dec\n",
    "df_a['Size'] = size_dec_norm\n",
    "\n",
    "df = df_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ByteOffset</th>\n",
       "      <th>IOSize</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255545344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33124147200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54056763392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15570624512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>732401823744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.624265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ByteOffset IOSize      Size\n",
       "0     255545344    NaN  0.000218\n",
       "1   33124147200    NaN  0.028233\n",
       "2   54056763392    NaN  0.046075\n",
       "3   15570624512    NaN  0.013272\n",
       "4  732401823744    NaN  0.624265"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ByteOffset_Delta'] = df['ByteOffset'] - df['ByteOffset'].shift(-1)\n",
    "df = df.drop(df.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ByteOffset_Delta'] = df['ByteOffset_Delta'].fillna(0)\n",
    "\n",
    "a = df['ByteOffset_Delta'].unique().tolist()\n",
    "operation_id_map = {}\n",
    "for i,id in enumerate(a): operation_id_map[id] = i \n",
    "df['ByteOffset_Delta_class'] = df['ByteOffset_Delta'].map(lambda x: operation_id_map[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = df['IOSize'].unique().tolist()\n",
    "# size_id_map = {}\n",
    "# for i,id in enumerate(a): size_id_map[id] = i \n",
    "# df['Size_class'] = df['IOSize'].map(lambda x: size_id_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "x = Counter(df['ByteOffset_Delta_class'])\n",
    "vals = {}\n",
    "vals =  x.most_common(1000)\n",
    "bo_list = []\n",
    "\n",
    "for x in vals:\n",
    "    bo_list.append(x[0])\n",
    "        \n",
    "count = 0\n",
    "label_list = []\n",
    "\n",
    "while (count < len(df)):\n",
    "    x = df['ByteOffset_Delta_class'].iloc[count]\n",
    "    if x in bo_list:\n",
    "        label_list.append(x)\n",
    "    else:\n",
    "        label_list.append(999999)\n",
    "    count= count + 1\n",
    "    \n",
    "ByteOffset_Delta_class_backup  = df['ByteOffset_Delta_class'] \n",
    "df['ByteOffset_Delta_class']  = label_list\n",
    "print(len(Counter(df['ByteOffset_Delta_class'])))\n",
    "    \n",
    "a = df['ByteOffset_Delta_class'].unique().tolist()\n",
    "bo_map = {}\n",
    "for i,id in enumerate(a): bo_map[id] = i \n",
    "df['ByteOffset_Delta_Class_1001'] = df['ByteOffset_Delta_class'].map(lambda x: bo_map[x])\n",
    "    \n",
    "label_list = df['ByteOffset_Delta_Class_1001'] \n",
    "    \n",
    "df['ByteOffset_Delta_Class_1001']  = label_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 584420,\n",
       "         1: 295,\n",
       "         2: 103,\n",
       "         3: 26,\n",
       "         4: 110,\n",
       "         5: 111,\n",
       "         6: 89,\n",
       "         7: 91,\n",
       "         8: 100,\n",
       "         9: 100,\n",
       "         10: 90,\n",
       "         11: 335,\n",
       "         12: 29173,\n",
       "         13: 2779,\n",
       "         14: 523,\n",
       "         15: 2035,\n",
       "         16: 404,\n",
       "         17: 942,\n",
       "         18: 32,\n",
       "         19: 110,\n",
       "         20: 110,\n",
       "         21: 99,\n",
       "         22: 97,\n",
       "         23: 93,\n",
       "         24: 2155,\n",
       "         25: 1033,\n",
       "         26: 364,\n",
       "         27: 5856,\n",
       "         28: 718,\n",
       "         29: 1509,\n",
       "         30: 1760,\n",
       "         31: 26,\n",
       "         32: 346,\n",
       "         33: 402,\n",
       "         34: 19,\n",
       "         35: 572,\n",
       "         36: 95,\n",
       "         37: 16,\n",
       "         38: 50,\n",
       "         39: 81,\n",
       "         40: 464,\n",
       "         41: 240,\n",
       "         42: 125,\n",
       "         43: 80,\n",
       "         44: 203,\n",
       "         45: 12,\n",
       "         46: 16,\n",
       "         47: 67,\n",
       "         48: 19,\n",
       "         49: 21867,\n",
       "         50: 13,\n",
       "         51: 33,\n",
       "         52: 19,\n",
       "         53: 70,\n",
       "         54: 1089,\n",
       "         55: 273,\n",
       "         56: 37,\n",
       "         57: 226,\n",
       "         58: 12,\n",
       "         59: 51,\n",
       "         60: 34,\n",
       "         61: 1816,\n",
       "         62: 93,\n",
       "         63: 497,\n",
       "         64: 30,\n",
       "         65: 11,\n",
       "         66: 12,\n",
       "         67: 116,\n",
       "         68: 137,\n",
       "         69: 11,\n",
       "         70: 78,\n",
       "         71: 82,\n",
       "         72: 61,\n",
       "         73: 25,\n",
       "         74: 52,\n",
       "         75: 26,\n",
       "         76: 21,\n",
       "         77: 284,\n",
       "         78: 64,\n",
       "         79: 43,\n",
       "         80: 265,\n",
       "         81: 16,\n",
       "         82: 93,\n",
       "         83: 464,\n",
       "         84: 91,\n",
       "         85: 153,\n",
       "         86: 207,\n",
       "         87: 189,\n",
       "         88: 34,\n",
       "         89: 46,\n",
       "         90: 112,\n",
       "         91: 17,\n",
       "         92: 2112,\n",
       "         93: 838,\n",
       "         94: 10,\n",
       "         95: 406,\n",
       "         96: 139,\n",
       "         97: 31,\n",
       "         98: 45,\n",
       "         99: 15,\n",
       "         100: 237,\n",
       "         101: 1288,\n",
       "         102: 166,\n",
       "         103: 222,\n",
       "         104: 120,\n",
       "         105: 84,\n",
       "         106: 198,\n",
       "         107: 160,\n",
       "         108: 64,\n",
       "         109: 33,\n",
       "         110: 661,\n",
       "         111: 77,\n",
       "         112: 64,\n",
       "         113: 277,\n",
       "         114: 10,\n",
       "         115: 146,\n",
       "         116: 46,\n",
       "         117: 60,\n",
       "         118: 57,\n",
       "         119: 60,\n",
       "         120: 22,\n",
       "         121: 16,\n",
       "         122: 13,\n",
       "         123: 11,\n",
       "         124: 11,\n",
       "         125: 10,\n",
       "         126: 84,\n",
       "         127: 615,\n",
       "         128: 54,\n",
       "         129: 22,\n",
       "         130: 74,\n",
       "         131: 362,\n",
       "         132: 33,\n",
       "         133: 108,\n",
       "         134: 129,\n",
       "         135: 144,\n",
       "         136: 30,\n",
       "         137: 691,\n",
       "         138: 83,\n",
       "         139: 95,\n",
       "         140: 91,\n",
       "         141: 35,\n",
       "         142: 365,\n",
       "         143: 106,\n",
       "         144: 26,\n",
       "         145: 30,\n",
       "         146: 99,\n",
       "         147: 24,\n",
       "         148: 76,\n",
       "         149: 97,\n",
       "         150: 104,\n",
       "         151: 382,\n",
       "         152: 49,\n",
       "         153: 126,\n",
       "         154: 871,\n",
       "         155: 77,\n",
       "         156: 60,\n",
       "         157: 30,\n",
       "         158: 70,\n",
       "         159: 150,\n",
       "         160: 28,\n",
       "         161: 171,\n",
       "         162: 77,\n",
       "         163: 99,\n",
       "         164: 66,\n",
       "         165: 89,\n",
       "         166: 21,\n",
       "         167: 32,\n",
       "         168: 75,\n",
       "         169: 82,\n",
       "         170: 19,\n",
       "         171: 69,\n",
       "         172: 79,\n",
       "         173: 114,\n",
       "         174: 154,\n",
       "         175: 92,\n",
       "         176: 181,\n",
       "         177: 571,\n",
       "         178: 11,\n",
       "         179: 69,\n",
       "         180: 31,\n",
       "         181: 210,\n",
       "         182: 520,\n",
       "         183: 12,\n",
       "         184: 11,\n",
       "         185: 21,\n",
       "         186: 71,\n",
       "         187: 16,\n",
       "         188: 23,\n",
       "         189: 44,\n",
       "         190: 19,\n",
       "         191: 27,\n",
       "         192: 65,\n",
       "         193: 111,\n",
       "         194: 23,\n",
       "         195: 71,\n",
       "         196: 17,\n",
       "         197: 10,\n",
       "         198: 45,\n",
       "         199: 49,\n",
       "         200: 34,\n",
       "         201: 12,\n",
       "         202: 86,\n",
       "         203: 45,\n",
       "         204: 87,\n",
       "         205: 148,\n",
       "         206: 90,\n",
       "         207: 115,\n",
       "         208: 201,\n",
       "         209: 35,\n",
       "         210: 120,\n",
       "         211: 21,\n",
       "         212: 33,\n",
       "         213: 78,\n",
       "         214: 72,\n",
       "         215: 29,\n",
       "         216: 20,\n",
       "         217: 13,\n",
       "         218: 28,\n",
       "         219: 14,\n",
       "         220: 315,\n",
       "         221: 370,\n",
       "         222: 89,\n",
       "         223: 13,\n",
       "         224: 39,\n",
       "         225: 49,\n",
       "         226: 51,\n",
       "         227: 33,\n",
       "         228: 10,\n",
       "         229: 81,\n",
       "         230: 10,\n",
       "         231: 26,\n",
       "         232: 14,\n",
       "         233: 63,\n",
       "         234: 25,\n",
       "         235: 124,\n",
       "         236: 79,\n",
       "         237: 10,\n",
       "         238: 29,\n",
       "         239: 43,\n",
       "         240: 243,\n",
       "         241: 14,\n",
       "         242: 46,\n",
       "         243: 50,\n",
       "         244: 23,\n",
       "         245: 55,\n",
       "         246: 19,\n",
       "         247: 13,\n",
       "         248: 60,\n",
       "         249: 62,\n",
       "         250: 141,\n",
       "         251: 42,\n",
       "         252: 226,\n",
       "         253: 14,\n",
       "         254: 13,\n",
       "         255: 13,\n",
       "         256: 40,\n",
       "         257: 16,\n",
       "         258: 125,\n",
       "         259: 109,\n",
       "         260: 30,\n",
       "         261: 18,\n",
       "         262: 22,\n",
       "         263: 11,\n",
       "         264: 13,\n",
       "         265: 28,\n",
       "         266: 13,\n",
       "         267: 126,\n",
       "         268: 14,\n",
       "         269: 11,\n",
       "         270: 23,\n",
       "         271: 20,\n",
       "         272: 22,\n",
       "         273: 65,\n",
       "         274: 33,\n",
       "         275: 83,\n",
       "         276: 119,\n",
       "         277: 13,\n",
       "         278: 237,\n",
       "         279: 41,\n",
       "         280: 78,\n",
       "         281: 94,\n",
       "         282: 52,\n",
       "         283: 128,\n",
       "         284: 47,\n",
       "         285: 136,\n",
       "         286: 15,\n",
       "         287: 74,\n",
       "         288: 20,\n",
       "         289: 61,\n",
       "         290: 11,\n",
       "         291: 42,\n",
       "         292: 11,\n",
       "         293: 19,\n",
       "         294: 75,\n",
       "         295: 13,\n",
       "         296: 11,\n",
       "         297: 11,\n",
       "         298: 11,\n",
       "         299: 129,\n",
       "         300: 11,\n",
       "         301: 51,\n",
       "         302: 34,\n",
       "         303: 78,\n",
       "         304: 40,\n",
       "         305: 26,\n",
       "         306: 12,\n",
       "         307: 17,\n",
       "         308: 13,\n",
       "         309: 15,\n",
       "         310: 12,\n",
       "         311: 297,\n",
       "         312: 118,\n",
       "         313: 25,\n",
       "         314: 44,\n",
       "         315: 44,\n",
       "         316: 23,\n",
       "         317: 29,\n",
       "         318: 11,\n",
       "         319: 36,\n",
       "         320: 86,\n",
       "         321: 20,\n",
       "         322: 16,\n",
       "         323: 76,\n",
       "         324: 23,\n",
       "         325: 21,\n",
       "         326: 62,\n",
       "         327: 36,\n",
       "         328: 15,\n",
       "         329: 15,\n",
       "         330: 13,\n",
       "         331: 14,\n",
       "         332: 11,\n",
       "         333: 27,\n",
       "         334: 11,\n",
       "         335: 14,\n",
       "         336: 11,\n",
       "         337: 12,\n",
       "         338: 16,\n",
       "         339: 12,\n",
       "         340: 14,\n",
       "         341: 13,\n",
       "         342: 16,\n",
       "         343: 12,\n",
       "         344: 12,\n",
       "         345: 11,\n",
       "         346: 42,\n",
       "         347: 69,\n",
       "         348: 20,\n",
       "         349: 30,\n",
       "         350: 12,\n",
       "         351: 57,\n",
       "         352: 11,\n",
       "         353: 11,\n",
       "         354: 46,\n",
       "         355: 31,\n",
       "         356: 52,\n",
       "         357: 26,\n",
       "         358: 58,\n",
       "         359: 76,\n",
       "         360: 13,\n",
       "         361: 14,\n",
       "         362: 61,\n",
       "         363: 53,\n",
       "         364: 14,\n",
       "         365: 12,\n",
       "         366: 24,\n",
       "         367: 24,\n",
       "         368: 33,\n",
       "         369: 24,\n",
       "         370: 11,\n",
       "         371: 13,\n",
       "         372: 60,\n",
       "         373: 190,\n",
       "         374: 13,\n",
       "         375: 17,\n",
       "         376: 14,\n",
       "         377: 59,\n",
       "         378: 46,\n",
       "         379: 65,\n",
       "         380: 32,\n",
       "         381: 25,\n",
       "         382: 30,\n",
       "         383: 24,\n",
       "         384: 20,\n",
       "         385: 15,\n",
       "         386: 27,\n",
       "         387: 41,\n",
       "         388: 16,\n",
       "         389: 12,\n",
       "         390: 31,\n",
       "         391: 11,\n",
       "         392: 12,\n",
       "         393: 182,\n",
       "         394: 14,\n",
       "         395: 11,\n",
       "         396: 13,\n",
       "         397: 29,\n",
       "         398: 78,\n",
       "         399: 19,\n",
       "         400: 22,\n",
       "         401: 89,\n",
       "         402: 14,\n",
       "         403: 105,\n",
       "         404: 13,\n",
       "         405: 15,\n",
       "         406: 12,\n",
       "         407: 12,\n",
       "         408: 12,\n",
       "         409: 11,\n",
       "         410: 51,\n",
       "         411: 154,\n",
       "         412: 11,\n",
       "         413: 26,\n",
       "         414: 11,\n",
       "         415: 11,\n",
       "         416: 28,\n",
       "         417: 12,\n",
       "         418: 15,\n",
       "         419: 11,\n",
       "         420: 11,\n",
       "         421: 59,\n",
       "         422: 25,\n",
       "         423: 33,\n",
       "         424: 15,\n",
       "         425: 19,\n",
       "         426: 46,\n",
       "         427: 15,\n",
       "         428: 14,\n",
       "         429: 15,\n",
       "         430: 16,\n",
       "         431: 96,\n",
       "         432: 12,\n",
       "         433: 16,\n",
       "         434: 11,\n",
       "         435: 11,\n",
       "         436: 13,\n",
       "         437: 12,\n",
       "         438: 11,\n",
       "         439: 11,\n",
       "         440: 16,\n",
       "         441: 30,\n",
       "         442: 26,\n",
       "         443: 12,\n",
       "         444: 13,\n",
       "         445: 21,\n",
       "         446: 33,\n",
       "         447: 13,\n",
       "         448: 15,\n",
       "         449: 12,\n",
       "         450: 11,\n",
       "         451: 29,\n",
       "         452: 39,\n",
       "         453: 482,\n",
       "         454: 21,\n",
       "         455: 18,\n",
       "         456: 11,\n",
       "         457: 15,\n",
       "         458: 24,\n",
       "         459: 38,\n",
       "         460: 16,\n",
       "         461: 27,\n",
       "         462: 21,\n",
       "         463: 13,\n",
       "         464: 22,\n",
       "         465: 28,\n",
       "         466: 16,\n",
       "         467: 13,\n",
       "         468: 11,\n",
       "         469: 15,\n",
       "         470: 11,\n",
       "         471: 14,\n",
       "         472: 17,\n",
       "         473: 15,\n",
       "         474: 11,\n",
       "         475: 18,\n",
       "         476: 37,\n",
       "         477: 12,\n",
       "         478: 14,\n",
       "         479: 43,\n",
       "         480: 76,\n",
       "         481: 43,\n",
       "         482: 341,\n",
       "         483: 13,\n",
       "         484: 27,\n",
       "         485: 122,\n",
       "         486: 16,\n",
       "         487: 61,\n",
       "         488: 13,\n",
       "         489: 14,\n",
       "         490: 37,\n",
       "         491: 62,\n",
       "         492: 17,\n",
       "         493: 11,\n",
       "         494: 11,\n",
       "         495: 464,\n",
       "         496: 16,\n",
       "         497: 14,\n",
       "         498: 27,\n",
       "         499: 21,\n",
       "         500: 23,\n",
       "         501: 19,\n",
       "         502: 12,\n",
       "         503: 426,\n",
       "         504: 13,\n",
       "         505: 14,\n",
       "         506: 12,\n",
       "         507: 48,\n",
       "         508: 70,\n",
       "         509: 31,\n",
       "         510: 11,\n",
       "         511: 12,\n",
       "         512: 14,\n",
       "         513: 23,\n",
       "         514: 21,\n",
       "         515: 13,\n",
       "         516: 11,\n",
       "         517: 51,\n",
       "         518: 11,\n",
       "         519: 16,\n",
       "         520: 32,\n",
       "         521: 12,\n",
       "         522: 15,\n",
       "         523: 11,\n",
       "         524: 21,\n",
       "         525: 18,\n",
       "         526: 37,\n",
       "         527: 25,\n",
       "         528: 13,\n",
       "         529: 12,\n",
       "         530: 61,\n",
       "         531: 43,\n",
       "         532: 13,\n",
       "         533: 222,\n",
       "         534: 15,\n",
       "         535: 11,\n",
       "         536: 14,\n",
       "         537: 21,\n",
       "         538: 12,\n",
       "         539: 13,\n",
       "         540: 12,\n",
       "         541: 13,\n",
       "         542: 25,\n",
       "         543: 343,\n",
       "         544: 22,\n",
       "         545: 16,\n",
       "         546: 18,\n",
       "         547: 14,\n",
       "         548: 12,\n",
       "         549: 19,\n",
       "         550: 15,\n",
       "         551: 17,\n",
       "         552: 17,\n",
       "         553: 15,\n",
       "         554: 11,\n",
       "         555: 13,\n",
       "         556: 11,\n",
       "         557: 22,\n",
       "         558: 56,\n",
       "         559: 16,\n",
       "         560: 64,\n",
       "         561: 13,\n",
       "         562: 12,\n",
       "         563: 66,\n",
       "         564: 11,\n",
       "         565: 14,\n",
       "         566: 11,\n",
       "         567: 84,\n",
       "         568: 15,\n",
       "         569: 22,\n",
       "         570: 28,\n",
       "         571: 51,\n",
       "         572: 13,\n",
       "         573: 15,\n",
       "         574: 58,\n",
       "         575: 12,\n",
       "         576: 17,\n",
       "         577: 11,\n",
       "         578: 66,\n",
       "         579: 14,\n",
       "         580: 63,\n",
       "         581: 17,\n",
       "         582: 12,\n",
       "         583: 15,\n",
       "         584: 14,\n",
       "         585: 30,\n",
       "         586: 16,\n",
       "         587: 17,\n",
       "         588: 62,\n",
       "         589: 18,\n",
       "         590: 17,\n",
       "         591: 16,\n",
       "         592: 14,\n",
       "         593: 15,\n",
       "         594: 183,\n",
       "         595: 17,\n",
       "         596: 31,\n",
       "         597: 49,\n",
       "         598: 37,\n",
       "         599: 14,\n",
       "         600: 24,\n",
       "         601: 658,\n",
       "         602: 660,\n",
       "         603: 19,\n",
       "         604: 38,\n",
       "         605: 1104,\n",
       "         606: 42,\n",
       "         607: 896,\n",
       "         608: 16,\n",
       "         609: 70,\n",
       "         610: 175,\n",
       "         611: 32,\n",
       "         612: 35,\n",
       "         613: 23,\n",
       "         614: 16,\n",
       "         615: 19,\n",
       "         616: 18,\n",
       "         617: 66,\n",
       "         618: 25,\n",
       "         619: 13,\n",
       "         620: 37,\n",
       "         621: 35,\n",
       "         622: 62,\n",
       "         623: 212,\n",
       "         624: 55,\n",
       "         625: 70,\n",
       "         626: 61,\n",
       "         627: 54,\n",
       "         628: 35,\n",
       "         629: 36,\n",
       "         630: 80,\n",
       "         631: 44,\n",
       "         632: 30,\n",
       "         633: 26,\n",
       "         634: 43,\n",
       "         635: 20,\n",
       "         636: 26,\n",
       "         637: 19,\n",
       "         638: 17,\n",
       "         639: 19,\n",
       "         640: 45,\n",
       "         641: 44,\n",
       "         642: 67,\n",
       "         643: 59,\n",
       "         644: 51,\n",
       "         645: 73,\n",
       "         646: 37,\n",
       "         647: 58,\n",
       "         648: 23,\n",
       "         649: 38,\n",
       "         650: 55,\n",
       "         651: 25,\n",
       "         652: 14,\n",
       "         653: 32,\n",
       "         654: 135,\n",
       "         655: 35,\n",
       "         656: 64,\n",
       "         657: 25,\n",
       "         658: 60,\n",
       "         659: 32,\n",
       "         660: 52,\n",
       "         661: 52,\n",
       "         662: 17,\n",
       "         663: 11,\n",
       "         664: 36,\n",
       "         665: 36,\n",
       "         666: 29,\n",
       "         667: 33,\n",
       "         668: 21,\n",
       "         669: 24,\n",
       "         670: 60,\n",
       "         671: 49,\n",
       "         672: 63,\n",
       "         673: 65,\n",
       "         674: 24,\n",
       "         675: 56,\n",
       "         676: 22,\n",
       "         677: 80,\n",
       "         678: 32,\n",
       "         679: 146,\n",
       "         680: 62,\n",
       "         681: 48,\n",
       "         682: 28,\n",
       "         683: 56,\n",
       "         684: 41,\n",
       "         685: 18,\n",
       "         686: 61,\n",
       "         687: 50,\n",
       "         688: 15,\n",
       "         689: 62,\n",
       "         690: 11,\n",
       "         691: 93,\n",
       "         692: 32,\n",
       "         693: 12,\n",
       "         694: 53,\n",
       "         695: 14,\n",
       "         696: 15,\n",
       "         697: 41,\n",
       "         698: 114,\n",
       "         699: 16,\n",
       "         700: 12,\n",
       "         701: 22,\n",
       "         702: 20,\n",
       "         703: 30,\n",
       "         704: 15,\n",
       "         705: 24,\n",
       "         706: 15,\n",
       "         707: 17,\n",
       "         708: 11,\n",
       "         709: 23,\n",
       "         710: 16,\n",
       "         711: 20,\n",
       "         712: 39,\n",
       "         713: 26,\n",
       "         714: 27,\n",
       "         715: 36,\n",
       "         716: 23,\n",
       "         717: 19,\n",
       "         718: 20,\n",
       "         719: 35,\n",
       "         720: 25,\n",
       "         721: 52,\n",
       "         722: 13,\n",
       "         723: 15,\n",
       "         724: 18,\n",
       "         725: 13,\n",
       "         726: 28,\n",
       "         727: 42,\n",
       "         728: 13,\n",
       "         729: 19,\n",
       "         730: 20,\n",
       "         731: 33,\n",
       "         732: 19,\n",
       "         733: 18,\n",
       "         734: 30,\n",
       "         735: 33,\n",
       "         736: 27,\n",
       "         737: 35,\n",
       "         738: 12,\n",
       "         739: 22,\n",
       "         740: 12,\n",
       "         741: 15,\n",
       "         742: 24,\n",
       "         743: 27,\n",
       "         744: 35,\n",
       "         745: 17,\n",
       "         746: 27,\n",
       "         747: 44,\n",
       "         748: 16,\n",
       "         749: 23,\n",
       "         750: 37,\n",
       "         751: 13,\n",
       "         752: 15,\n",
       "         753: 21,\n",
       "         754: 11,\n",
       "         755: 36,\n",
       "         756: 25,\n",
       "         757: 25,\n",
       "         758: 24,\n",
       "         759: 16,\n",
       "         760: 19,\n",
       "         761: 64,\n",
       "         762: 14,\n",
       "         763: 27,\n",
       "         764: 27,\n",
       "         765: 58,\n",
       "         766: 24,\n",
       "         767: 48,\n",
       "         768: 43,\n",
       "         769: 29,\n",
       "         770: 19,\n",
       "         771: 15,\n",
       "         772: 17,\n",
       "         773: 20,\n",
       "         774: 23,\n",
       "         775: 27,\n",
       "         776: 14,\n",
       "         777: 16,\n",
       "         778: 16,\n",
       "         779: 48,\n",
       "         780: 30,\n",
       "         781: 36,\n",
       "         782: 18,\n",
       "         783: 15,\n",
       "         784: 17,\n",
       "         785: 36,\n",
       "         786: 20,\n",
       "         787: 17,\n",
       "         788: 12,\n",
       "         789: 24,\n",
       "         790: 12,\n",
       "         791: 20,\n",
       "         792: 14,\n",
       "         793: 33,\n",
       "         794: 20,\n",
       "         795: 30,\n",
       "         796: 25,\n",
       "         797: 38,\n",
       "         798: 21,\n",
       "         799: 21,\n",
       "         800: 21,\n",
       "         801: 28,\n",
       "         802: 24,\n",
       "         803: 23,\n",
       "         804: 33,\n",
       "         805: 30,\n",
       "         806: 36,\n",
       "         807: 26,\n",
       "         808: 11,\n",
       "         809: 13,\n",
       "         810: 83,\n",
       "         811: 13,\n",
       "         812: 37,\n",
       "         813: 12,\n",
       "         814: 11,\n",
       "         815: 17,\n",
       "         816: 15,\n",
       "         817: 13,\n",
       "         818: 17,\n",
       "         819: 14,\n",
       "         820: 12,\n",
       "         821: 24,\n",
       "         822: 21,\n",
       "         823: 20,\n",
       "         824: 11,\n",
       "         825: 20,\n",
       "         826: 24,\n",
       "         827: 11,\n",
       "         828: 11,\n",
       "         829: 24,\n",
       "         830: 17,\n",
       "         831: 17,\n",
       "         832: 22,\n",
       "         833: 23,\n",
       "         834: 45,\n",
       "         835: 39,\n",
       "         836: 19,\n",
       "         837: 12,\n",
       "         838: 26,\n",
       "         839: 19,\n",
       "         840: 31,\n",
       "         841: 11,\n",
       "         842: 18,\n",
       "         843: 13,\n",
       "         844: 13,\n",
       "         845: 11,\n",
       "         846: 53,\n",
       "         847: 12,\n",
       "         848: 11,\n",
       "         849: 13,\n",
       "         850: 11,\n",
       "         851: 22,\n",
       "         852: 16,\n",
       "         853: 12,\n",
       "         854: 29,\n",
       "         855: 18,\n",
       "         856: 12,\n",
       "         857: 11,\n",
       "         858: 14,\n",
       "         859: 12,\n",
       "         860: 13,\n",
       "         861: 12,\n",
       "         862: 24,\n",
       "         863: 12,\n",
       "         864: 15,\n",
       "         865: 11,\n",
       "         866: 19,\n",
       "         867: 12,\n",
       "         868: 11,\n",
       "         869: 12,\n",
       "         870: 11,\n",
       "         871: 11,\n",
       "         872: 13,\n",
       "         873: 21,\n",
       "         874: 23,\n",
       "         875: 14,\n",
       "         876: 32,\n",
       "         877: 13,\n",
       "         878: 15,\n",
       "         879: 12,\n",
       "         880: 19,\n",
       "         881: 15,\n",
       "         882: 14,\n",
       "         883: 14,\n",
       "         884: 19,\n",
       "         885: 16,\n",
       "         886: 11,\n",
       "         887: 28,\n",
       "         888: 18,\n",
       "         889: 14,\n",
       "         890: 15,\n",
       "         891: 11,\n",
       "         892: 11,\n",
       "         893: 13,\n",
       "         894: 12,\n",
       "         895: 16,\n",
       "         896: 11,\n",
       "         897: 11,\n",
       "         898: 11,\n",
       "         899: 12,\n",
       "         900: 11,\n",
       "         901: 13,\n",
       "         902: 16,\n",
       "         903: 17,\n",
       "         904: 12,\n",
       "         905: 15,\n",
       "         906: 16,\n",
       "         907: 14,\n",
       "         908: 35,\n",
       "         909: 16,\n",
       "         910: 11,\n",
       "         911: 12,\n",
       "         912: 13,\n",
       "         913: 14,\n",
       "         914: 15,\n",
       "         915: 14,\n",
       "         916: 19,\n",
       "         917: 16,\n",
       "         918: 16,\n",
       "         919: 13,\n",
       "         920: 13,\n",
       "         921: 13,\n",
       "         922: 17,\n",
       "         923: 13,\n",
       "         924: 29,\n",
       "         925: 17,\n",
       "         926: 21,\n",
       "         927: 11,\n",
       "         928: 17,\n",
       "         929: 21,\n",
       "         930: 19,\n",
       "         931: 15,\n",
       "         932: 11,\n",
       "         933: 17,\n",
       "         934: 13,\n",
       "         935: 14,\n",
       "         936: 12,\n",
       "         937: 11,\n",
       "         938: 14,\n",
       "         939: 13,\n",
       "         940: 11,\n",
       "         941: 14,\n",
       "         942: 15,\n",
       "         943: 11,\n",
       "         944: 55,\n",
       "         945: 21,\n",
       "         946: 13,\n",
       "         947: 11,\n",
       "         948: 42,\n",
       "         949: 22,\n",
       "         950: 13,\n",
       "         951: 16,\n",
       "         952: 32,\n",
       "         953: 13,\n",
       "         954: 11,\n",
       "         955: 12,\n",
       "         956: 11,\n",
       "         957: 54,\n",
       "         958: 11,\n",
       "         959: 12,\n",
       "         960: 14,\n",
       "         961: 12,\n",
       "         962: 15,\n",
       "         963: 13,\n",
       "         964: 12,\n",
       "         965: 11,\n",
       "         966: 14,\n",
       "         967: 14,\n",
       "         968: 11,\n",
       "         969: 12,\n",
       "         970: 21,\n",
       "         971: 14,\n",
       "         972: 12,\n",
       "         973: 13,\n",
       "         974: 13,\n",
       "         975: 11,\n",
       "         976: 12,\n",
       "         977: 12,\n",
       "         978: 14,\n",
       "         979: 14,\n",
       "         980: 21,\n",
       "         981: 11,\n",
       "         982: 14,\n",
       "         983: 12,\n",
       "         984: 11,\n",
       "         985: 11,\n",
       "         986: 13,\n",
       "         987: 11,\n",
       "         988: 15,\n",
       "         989: 11,\n",
       "         990: 22,\n",
       "         991: 15,\n",
       "         992: 13,\n",
       "         993: 18,\n",
       "         994: 21,\n",
       "         995: 17,\n",
       "         996: 15,\n",
       "         997: 11,\n",
       "         998: 15,\n",
       "         999: 11,\n",
       "         ...})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Counter(df['ByteOffset_Delta_Class_1001']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ByteOffset</th>\n",
       "      <th>IOSize</th>\n",
       "      <th>Size</th>\n",
       "      <th>ByteOffset_Delta</th>\n",
       "      <th>ByteOffset_Delta_class</th>\n",
       "      <th>ByteOffset_Delta_Class_1001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255545344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>-3.286860e+10</td>\n",
       "      <td>999999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33124147200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028233</td>\n",
       "      <td>-2.093262e+10</td>\n",
       "      <td>999999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54056763392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046075</td>\n",
       "      <td>3.848614e+10</td>\n",
       "      <td>999999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15570624512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013272</td>\n",
       "      <td>-7.168312e+11</td>\n",
       "      <td>999999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>732401823744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.624265</td>\n",
       "      <td>-1.901793e+09</td>\n",
       "      <td>999999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ByteOffset IOSize      Size  ByteOffset_Delta  ByteOffset_Delta_class  \\\n",
       "0     255545344    NaN  0.000218     -3.286860e+10                  999999   \n",
       "1   33124147200    NaN  0.028233     -2.093262e+10                  999999   \n",
       "2   54056763392    NaN  0.046075      3.848614e+10                  999999   \n",
       "3   15570624512    NaN  0.013272     -7.168312e+11                  999999   \n",
       "4  732401823744    NaN  0.624265     -1.901793e+09                  999999   \n",
       "\n",
       "   ByteOffset_Delta_Class_1001  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ByteOffset                       int64\n",
       "IOSize                          object\n",
       "Size                           float64\n",
       "ByteOffset_Delta               float64\n",
       "ByteOffset_Delta_class           int64\n",
       "ByteOffset_Delta_Class_1001      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396734\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(len(Counter(df['Size'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396734"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(df['Size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to train, validate and test\n",
    "\n",
    "# Finding the value 75th percentile of TimeStamp\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "training_pt_1 = math.floor((len(df)*0.75)) \n",
    "\n",
    "lba_train =df[:training_pt_1]['ByteOffset_Delta_Class_1001'].tolist()\n",
    "lba_test = df[training_pt_1+1:]['ByteOffset_Delta_Class_1001'].tolist()\n",
    "size_train = df[:training_pt_1]['Size'].tolist()\n",
    "size_test = df[training_pt_1+1:]['Size'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lba_train= np.array(lba_train).reshape(-1,1)\n",
    "lba_test= np.array(lba_test).reshape(-1,1)\n",
    "size_train= np.array(size_train).reshape(-1,1)\n",
    "size_test= np.array(size_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_train = np.arange(1,101, dtype='float64').reshape(-1,1)  \n",
    "# ts_test = np.arange(21,41, dtype='float64').reshape(-1,1)\n",
    "# ts_all = np.append(ts_train, ts_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset2(dataset, window_size):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - 2 * window_size):\n",
    "        a = dataset[i:(i + window_size), 0]\n",
    "        #print(a)\n",
    "        dataX.append(a)\n",
    "        b = dataset[(i + window_size):(i + 2* window_size), 0]\n",
    "        #print(b)\n",
    "        dataY.append(b)\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "lstm_num_timesteps = 32\n",
    "    \n",
    "X_train_lba, y_train_lba = create_dataset2(lba_train, lstm_num_timesteps)\n",
    "X_test_lba, y_test_lba = create_dataset2(lba_test, lstm_num_timesteps)\n",
    "X_train_size, y_train_size = create_dataset2(size_train, lstm_num_timesteps)\n",
    "X_test_size, y_test_size = create_dataset2(size_test, lstm_num_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((535548, 32), (535548, 32), (178473, 32), (178473, 32))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lba.shape, y_train_lba.shape, X_test_lba.shape,  y_test_lba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((535548, 32), (535548, 32), (178473, 32), (178473, 32))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_size.shape, y_train_size.shape, X_test_size.shape,  y_test_size.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_num_features = 1\n",
    "lstm_predict_sequences = True\n",
    "lstm_num_predictions = 32\n",
    "\n",
    "\n",
    "# X_train = np.reshape(X_train, (X_train.shape[0], lstm_num_timesteps, lstm_num_features))\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], lstm_num_timesteps, lstm_num_features))\n",
    "    \n",
    "\n",
    "y_train_lba = np.reshape(y_train_lba, (y_train_lba.shape[0], lstm_num_predictions, lstm_num_features))\n",
    "y_test_lba = np.reshape(y_test_lba, (y_test_lba.shape[0], lstm_num_predictions, lstm_num_features))\n",
    "y_train_size = np.reshape(y_train_size, (y_train_size.shape[0], lstm_num_predictions, lstm_num_features))\n",
    "y_test_size = np.reshape(y_test_size, (y_test_size.shape[0], lstm_num_predictions, lstm_num_features))                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(535548, 32, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_lba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 32, 500)      500500      input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 32, 500)      25000       input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 1000)     0           embedding_9[0][0]                \n",
      "                                                                 embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (None, 32, 500)      3002000     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  (None, 32, 500)      2002000     lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "offset (TimeDistributed)        (None, 32, 1001)     501501      lstm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "iosize (TimeDistributed)        (None, 32, 1)        501         lstm_10[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,031,502\n",
      "Trainable params: 6,031,502\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Two classification outputs\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate , Dot\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout, TimeDistributed, Reshape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# no_docs = len(y_train_lba)\n",
    "maxlen= 32\n",
    "\n",
    "\n",
    "\n",
    "# # define two sets of inputs\n",
    "# inputA = Input(shape=(32,))\n",
    "# inputB = Input(shape=(32,))\n",
    "# # inputA = Sequential()\n",
    "# # inputB = Sequential()\n",
    "vocabulary_1 = len(Counter(df['ByteOffset_Delta_Class_1001']))\n",
    "vocabulary_2 = 50\n",
    "\n",
    "hidden_size = 500\n",
    "\n",
    "# input=Input(shape=(no_docs,maxlen),dtype='float64')\n",
    "inputA=Input(shape=(maxlen,),dtype='float64')  \n",
    "inputB=Input(shape=(maxlen,),dtype='float64') \n",
    "\n",
    "\n",
    "# the first branch operates on the first input\n",
    "x = Embedding(input_dim=vocabulary_1,output_dim=hidden_size,input_length=maxlen)(inputA)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "\n",
    "# # the second branch opreates on the second input\n",
    "y = Embedding(input_dim=vocabulary_2,output_dim=hidden_size,input_length=maxlen)(inputB)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "# combine the output of the two branches\n",
    "combined = keras.layers.concatenate([x.output, y.output])\n",
    "\n",
    "lstm1 = LSTM(hidden_size,return_sequences=True)(combined)\n",
    "lstm2 = LSTM(hidden_size, return_sequences=True)(lstm1)\n",
    "\n",
    "# create classification output\n",
    "offset = keras.layers.wrappers.TimeDistributed(Dense(units=vocabulary_1, activation='softmax'), name='offset')(lstm2)\n",
    "iosize = keras.layers.wrappers.TimeDistributed(Dense(units=1, activation='sigmoid'), name='iosize')(lstm2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model =Model([inputA,inputB],[offset,iosize]) # combining all into a Keras model\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'offset': 'sparse_categorical_crossentropy', 'iosize': 'mse'},\n",
    "              loss_weights={'offset': 2., 'iosize': 1.5},\n",
    "              metrics={ 'offset': 'categorical_accuracy', 'iosize': 'mae'})\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/1000\n",
      "535548/535548 [==============================] - 1448s 3ms/step - loss: 1.7175 - offset_loss: 0.8028 - iosize_loss: 0.0746 - offset_categorical_accuracy: 0.8977 - iosize_mae: 0.1974\n",
      "Epoch 2/1000\n",
      "535548/535548 [==============================] - 1466s 3ms/step - loss: 1.5400 - offset_loss: 0.7153 - iosize_loss: 0.0730 - offset_categorical_accuracy: 0.8858 - iosize_mae: 0.1953\n",
      "Epoch 3/1000\n",
      "535548/535548 [==============================] - 1451s 3ms/step - loss: 1.4668 - offset_loss: 0.6793 - iosize_loss: 0.0721 - offset_categorical_accuracy: 0.8803 - iosize_mae: 0.1934\n",
      "Epoch 4/1000\n",
      "535548/535548 [==============================] - 1447s 3ms/step - loss: 1.4291 - offset_loss: 0.6607 - iosize_loss: 0.0718 - offset_categorical_accuracy: 0.8777 - iosize_mae: 0.1936\n",
      "Epoch 5/1000\n",
      "535548/535548 [==============================] - 1454s 3ms/step - loss: 1.4107 - offset_loss: 0.6516 - iosize_loss: 0.0717 - offset_categorical_accuracy: 0.8760 - iosize_mae: 0.1935\n",
      "Epoch 6/1000\n",
      "535548/535548 [==============================] - 1470s 3ms/step - loss: 1.3986 - offset_loss: 0.6456 - iosize_loss: 0.0716 - offset_categorical_accuracy: 0.8749 - iosize_mae: 0.1936\n",
      "Epoch 7/1000\n",
      "535548/535548 [==============================] - 1468s 3ms/step - loss: 1.3938 - offset_loss: 0.6432 - iosize_loss: 0.0717 - offset_categorical_accuracy: 0.8744 - iosize_mae: 0.1937\n",
      "Epoch 8/1000\n",
      "535548/535548 [==============================] - 1480s 3ms/step - loss: 1.3883 - offset_loss: 0.6405 - iosize_loss: 0.0715 - offset_categorical_accuracy: 0.8735 - iosize_mae: 0.1930\n",
      "Epoch 9/1000\n",
      "535548/535548 [==============================] - 1458s 3ms/step - loss: 1.3870 - offset_loss: 0.6397 - iosize_loss: 0.0718 - offset_categorical_accuracy: 0.8729 - iosize_mae: 0.1940\n",
      "Epoch 10/1000\n",
      "535548/535548 [==============================] - 1442s 3ms/step - loss: 1.3882 - offset_loss: 0.6402 - iosize_loss: 0.0718 - offset_categorical_accuracy: 0.8737 - iosize_mae: 0.1944\n",
      "Epoch 11/1000\n",
      "535548/535548 [==============================] - 1441s 3ms/step - loss: 1.3956 - offset_loss: 0.6439 - iosize_loss: 0.0718 - offset_categorical_accuracy: 0.8745 - iosize_mae: 0.1938\n",
      "Epoch 12/1000\n",
      "535548/535548 [==============================] - 1459s 3ms/step - loss: 1.4062 - offset_loss: 0.6493 - iosize_loss: 0.0717 - offset_categorical_accuracy: 0.8751 - iosize_mae: 0.1933\n",
      "Epoch 13/1000\n",
      "271424/535548 [==============>...............] - ETA: 12:06 - loss: 1.4078 - offset_loss: 0.6500 - iosize_loss: 0.0719 - offset_categorical_accuracy: 0.8750 - iosize_mae: 0.1937"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-383d8090faf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m model.fit([X_train_lba,X_train_size],[y_train_lba,y_train_size],\n\u001b[0;32m---> 14\u001b[0;31m           verbose=1,epochs=1000,callbacks=[monitor,checkpointer])\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_weights-1.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load weights from best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3_tf_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/py3_tf_gpu/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    190\u001b[0m                                     'pass shuffle=\"batch\".')\n\u001b[1;32m    191\u001b[0m                 \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3_tf_gpu/lib/python3.6/site-packages/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m     90\u001b[0m            \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.95\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3_tf_gpu/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3493\u001b[0m     \"\"\"\n\u001b[1;32m   3494\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3495\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3496\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3497\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3_tf_gpu/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3377\u001b[0m     \"\"\"\n\u001b[0;32m-> 3378\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3379\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3380\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3_tf_gpu/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mset_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \"\"\"Convert the input to an ndarray, but pass ndarray subclasses through.\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_epochs = 1000\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "monitor = EarlyStopping(monitor='loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weights-1.hdf5\", verbose=1, save_best_only=True) # save best model\n",
    "\n",
    "\n",
    "print('Train...')\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit([X_train_lba,X_train_size],[y_train_lba,y_train_size],\n",
    "          verbose=1,epochs=1000,callbacks=[monitor,checkpointer])\n",
    "\n",
    "model.load_weights('best_weights-1.hdf5') # load weights from best model\n",
    "print('Done ...!')\n",
    "\n",
    "#model.fit(X_train, y_train, nb_epoch = num_epochs, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "178473/178473 [==============================] - 200s 1ms/step\n",
      "--- 200.26941204071045 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print('Predicting...')\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "pred1,pred2 = model.predict([X_test_lba,X_test_size],verbose = 1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178473"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = pred1[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178473,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_11.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_11 = np.argmax(pred_1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178537"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lba_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lba_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lba_test) \n",
    "test = lba_test[-178473:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(pred_111)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154661.0\n"
     ]
    }
   ],
   "source": [
    "#tmp_lba = accuracy_score(y_test_lba, pred_111)\n",
    "\n",
    "hit = 0\n",
    "count = 0\n",
    "while(count < len(predictions)):\n",
    "    if (test[count] == predictions[count]):\n",
    "        hit = hit +1\n",
    "    count = count +1\n",
    "    \n",
    "print(hit/len(predictions))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8665792584872782\n"
     ]
    }
   ],
   "source": [
    "print(hit/len(predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_111 = np.array(pred_11).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178537"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lba_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of unknown and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-b43c74473663>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtmp_lba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_lba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtmp_lba\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_lba_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmax_lba_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_lba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3_tf_gpu/lib/python3.6/site-packages/scikit_learn-0.21.2-py3.6-linux-x86_64.egg/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3_tf_gpu/lib/python3.6/site-packages/scikit_learn-0.21.2-py3.6-linux-x86_64.egg/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of unknown and multiclass targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "max_lba_accuracy = 0\n",
    "max_lba_accuracy_pos = 0\n",
    "\n",
    "min_mse_accuracy = 10000\n",
    "min_mse_accuracy_pos = 0\n",
    "\n",
    "for i in range(32):\n",
    "    pred_1 = pred1[:,i,:]\n",
    "    pred_2 = pred2[:,i,:]\n",
    "    pred_1 = np.argmax(pred_1, axis=1)\n",
    "    pred_2 = np.argmax(pred_2, axis=1)\n",
    "    \n",
    "    \n",
    "    tmp_lba = accuracy_score(y_test_lba, pred_1)\n",
    "    if (tmp_lba > max_lba_accuracy):\n",
    "        max_lba_accuracy = tmp_lba\n",
    "        max_lba_accuracy_pos = i\n",
    "        \n",
    "    tmp_size = criterion = mean_squared_error(y_test_size, pred_2)\n",
    "    if (tmp_size < min_mse_accuracy):\n",
    "        min_mse_accuracy = tmp_size\n",
    "        min_mse_accuracy_pos = i\n",
    "    \n",
    "\n",
    "print(\"Min IO Size MSE\", str(min_mse_accuracy))\n",
    "print(\"Min IO Size MSE Position\", str(min_mse_accuracy_pos))\n",
    "\n",
    "print(\"Best LBA Delta Accuracy\", str(max_lba_accuracy))\n",
    "print(\"Best LBA Delta Position\", str(max_lba_accuracy_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done...!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3_tf_gpu] *",
   "language": "python",
   "name": "conda-env-py3_tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
